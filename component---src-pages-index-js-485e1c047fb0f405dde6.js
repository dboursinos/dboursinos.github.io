(window.webpackJsonp=window.webpackJsonp||[]).push([[5],{"/tX2":function(e,t,a){e.exports=a.p+"static/representation_mapping-a908741c11fb568d3ff74278c85018f6.svg"},"7W2i":function(e,t,a){var n=a("SksO");e.exports=function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Super expression must either be null or a function");e.prototype=Object.create(t&&t.prototype,{constructor:{value:e,writable:!0,configurable:!0}}),t&&n(e,t)}},Bnag:function(e,t){e.exports=function(){throw new TypeError("Invalid attempt to spread non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}},EbDI:function(e,t){e.exports=function(e){if("undefined"!=typeof Symbol&&Symbol.iterator in Object(e))return Array.from(e)}},EuHx:function(e,t,a){e.exports=a.p+"static/sequencies_feedback-3761e5ba5b2972def5c160f2e796d932.png"},Fxm3:function(e,t,a){"use strict";a("HAE/"),Object.defineProperty(t,"__esModule",{value:!0}),t.default=void 0;var n=function(e){var t,a,n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:100;return function(){var i=+new Date;!!t&&i<t+n?(clearTimeout(a),a=setTimeout((function(){t=i,e()}),n)):(t=i,e())}};t.default=n},Ijbi:function(e,t,a){var n=a("WkPL");e.exports=function(e){if(Array.isArray(e))return n(e)}},ImdL:function(e,t,a){},IwmZ:function(e,t,a){e.exports=a.p+"static/detection_example-cdb1c2986dd7d1348efb807f90c407fc.png"},LbtI:function(e,t,a){e.exports=a.p+"static/object_detection_distance_learning_testing-a10f870054091d772568e31fba1bd187.svg"},Nsbk:function(e,t){function a(t){return e.exports=a=Object.setPrototypeOf?Object.getPrototypeOf:function(e){return e.__proto__||Object.getPrototypeOf(e)},a(t)}e.exports=a},RIqP:function(e,t,a){var n=a("Ijbi"),i=a("EbDI"),o=a("ZhPi"),s=a("Bnag");e.exports=function(e){return n(e)||i(e)||o(e)||s()}},RXBc:function(e,t,a){"use strict";a.r(t);var n=a("q1tI"),i=a.n(n),o=(a("ImdL"),a("7oih")),s=a("YIkO"),r=a.n(s),l=a("dwco"),c=a.n(l);function m(e){if(void 0===e)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return e}var d=function(e){return e.children},u=function(e){var t,a;function n(){var t;return(t=e.call(this)||this).handleClick=t.handleClick.bind(m(t)),t.handleKey=t.handleKey.bind(m(t)),t}a=e,(t=n).prototype=Object.create(a.prototype),t.prototype.constructor=t,t.__proto__=a;var o=n.prototype;return o.componentDidMount=function(){c.a.polyfill()},o.handleKey=function(e){console.log("handling key: "+e.keyCode)},o.handleClick=function(e){e.preventDefault();var t=0,a=!0,n=this.props,i=n.type,o=n.element,s=n.offset,r=n.timeout;if(i&&o)switch(i){case"class":a=!!(t=document.getElementsByClassName(o)[0]);break;case"id":a=!!(t=document.getElementById(o))}a?this.scrollTo(t,s,r):console.log("Element not found: "+o)},o.scrollTo=function(e,t,a){void 0===t&&(t=0),void 0===a&&(a=null);var n=e?e.getBoundingClientRect().top+window.pageYOffset:0;a?setTimeout((function(){window.scroll({top:n+t,left:0,behavior:"smooth"})}),a):window.scroll({top:n+t,left:0,behavior:"smooth"})},o.render=function(){return i.a.createElement(d,null,"object"==typeof this.props.children?i.a.cloneElement(this.props.children,{onClick:this.handleClick}):i.a.createElement("span",{onClick:this.handleClick,onKeyUp:this.handleKey},this.props.children))},n}(i.a.Component),h=a("ku9C"),p=a.n(h),f=a("obyI"),b=a.n(f);var g=function(e){var t,a;function n(t){var a;return(a=e.call(this,t)||this).state={tabs:[{content:"About",href:"about"},{content:"Education",href:"education"},{content:"Experience",href:"experience"},{content:"Skills",href:"skills"},{content:"Awards",href:"awards"},{content:"Publications",href:"publications"},{content:"Practical Applications",href:"research"}],collapsed:!0},a.toggleNavbar=a.toggleNavbar.bind(function(e){if(void 0===e)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return e}(a)),a}a=e,(t=n).prototype=Object.create(a.prototype),t.prototype.constructor=t,t.__proto__=a;var o=n.prototype;return o.toggleNavbar=function(){this.setState({collapsed:!this.state.collapsed,tabs:this.state.tabs}),console.log("state: ",this.state)},o.render=function(){var e=this,t=this.state.collapsed,a=t?"collapse navbar-collapse":"collapse navbar-collapse show",n=t?"navbar-toggler navbar-toggler-right collapsed":"navbar-toggler navbar-toggler-right",o=this.state.tabs;return i.a.createElement("nav",{className:"navbar navbar-expand-lg navbar-dark bg-primary fixed-top",id:"sideNav"},i.a.createElement("a",{className:"navbar-brand",href:"#about"},i.a.createElement("span",{className:"d-block d-lg-none"},b.a.firstName," ",b.a.lastName),i.a.createElement("span",{className:"d-none d-lg-block"},i.a.createElement("img",{className:"img-fluid img-profile rounded-circle mx-auto mb-2",src:p.a,alt:""}))),i.a.createElement("button",{className:""+n,type:"button","aria-controls":"navbarSupportedContent","aria-expanded":"false","aria-label":"Toggle navigation",onClick:this.toggleNavbar},i.a.createElement("span",{className:"navbar-toggler-icon"})),i.a.createElement("div",{className:""+a,id:"navbarSupportedContent"},i.a.createElement(r.a,{items:o.map((function(e){return e.href})),currentClassName:"active",offset:-300,className:"navbar-nav"},o.map((function(t,a){var n=t.href,o=t.content;return i.a.createElement("li",{className:"nav-item",key:n,onClick:e.trackClick},i.a.createElement(u,{type:"id",element:n},i.a.createElement("a",{className:"nav-link",href:"#"+n},o)))})))))},n}(n.Component),y=a("d/Oy"),v=a.n(y);function E(){return i.a.createElement("section",{className:"resume-section p-3 p-lg-5 d-flex align-items-center",id:"about"},i.a.createElement("div",{className:"w-100"},i.a.createElement("div",{className:"row"},i.a.createElement("div",{className:"col-md-10 col-sm-12"},i.a.createElement("h1",{className:"mb-0"},b.a.firstName,i.a.createElement("span",{className:"text-primary"},b.a.lastName))),i.a.createElement("div",{className:"d-print-none col-md-2 text-right col-sm-12 row pt-4"},i.a.createElement("div",{className:"col-md-auto col-sm-12 pb-4"},i.a.createElement("a",{href:v.a,target:"_blank",rel:"noopener noreferrer"},i.a.createElement("button",{className:"btn btn-primary btn-block"}," ",i.a.createElement("i",{className:"fab fa-adobe"})," PDF"))))),i.a.createElement("div",{className:"subheading mb-5"},b.a.address," Â·",i.a.createElement("a",{href:"mailto:"+b.a.email},b.a.email)),i.a.createElement("p",{className:"lead mb-3"},"Research Assistant PhD student at Vanderbilt University"),i.a.createElement("p",{className:"lead mb-3"},"I believe that evolved, empathic problem solving involves clear assessment of reality, honest & transparent communications, and the capability to push through to results. ",i.a.createElement("em",null," I make this work my art.")),i.a.createElement("p",{className:"lead mb-3"},"I intend to bring value crafting elegant interfaces & experiences, identifying & pursuing growth opportunities, and building software that aligns with my dream of voluntary interactions for all individuals, and a society free from coercion."),i.a.createElement("small",null,i.a.createElement("p",null))))}function w(){return i.a.createElement("section",{className:"resume-section p-3 p-lg-5 d-flex align-items-center",id:"education"},i.a.createElement("div",{className:"w-100"},i.a.createElement("h2",{className:"mb-5"},"Education"),i.a.createElement("div",{className:"resume-item d-flex flex-column flex-md-row justify-content-between mb-5"},i.a.createElement("div",{className:"resume-content"},i.a.createElement("h3",{className:"mb-0"},"Vanderbilt University"),i.a.createElement("div",{className:"subheading mb-3"},"PhD & MS, Electrical Engineering, GPA 3.88/4"),i.a.createElement("div",{className:"subheading mb-3"},"Related Coursework:"),i.a.createElement("p",null,"Cyber-Physical Systems; Detection & Estimation Theory; Network Security; Model Integrated Computing; Statistical Pattern Recognition; Design & Analysis of Algorithms; Advanced Real-Time Systems")),i.a.createElement("div",{className:"resume-date text-md-right"},i.a.createElement("span",{className:"text-primary"},"2016 - 2021"))),i.a.createElement("div",{className:"resume-item d-flex flex-column flex-md-row justify-content-between mb-5"},i.a.createElement("div",{className:"resume-content"},i.a.createElement("h3",{className:"mb-0"},"University of Patras"),i.a.createElement("div",{className:"subheading mb-3"},"MS & BS, Electrical and Computer Engineering"),i.a.createElement("div",{className:"subheading mb-3"},"Related Coursework:"),i.a.createElement("p",null,"Algorithms & Data Structures; Pattern Recognition; Natural Language Technology; Intelligent Control; Microcomputers; Automatic Control Systems; Digital Control Systems; Electrical Machines I & II; Design of Dynamical Systems; Adaptive Control; Robotic Systems; Adaptive Control; Nonlinear Control")),i.a.createElement("div",{className:"resume-date text-md-right"},i.a.createElement("span",{className:"text-primary"},"2010 - 2016")))))}function N(){return i.a.createElement("section",{className:"resume-section p-3 p-lg-5 d-flex justify-content-center",id:"experience"},i.a.createElement("div",{className:"w-100"},i.a.createElement("h2",{className:"mb-5"},"Experience"),i.a.createElement("div",{className:"resume-item d-flex flex-column flex-md-row justify-content-between mb-5"},i.a.createElement("div",{className:"resume-content"},i.a.createElement("h3",{className:"mb-0"},"Research Assistant, Assured Autonomy"),i.a.createElement("div",{className:"subheading mb-3"},"Vanderbilt University: Nashville, TN "),i.a.createElement("p",null,i.a.createElement("ul",null,i.a.createElement("li",null,"Developed robust and well-calibrated assurance monitors for machine learning components. Evaluated and tested in realistic autonomous driving scenarios."),i.a.createElement("li",null,"Reduced the memory requirements and execution time of calibrated machine learning components by 99% (empirical evaluation in autonomous driving functions) without compromising accuracy by using low-dimensional appropriate representations of the original data."),i.a.createElement("li",null,"Developed robust visual perception for object detection on camera data for autonomous vehicle applications."),i.a.createElement("li",null,"Developed algorithms to compute appropriate significance levels regarding machine learning model decisions to reduce the times human intervention is necessary. Our evaluation showed more than 99.9% autonomous operation in all the test cases."),i.a.createElement("li",null,"Working on producing well-calibrated confidence metrics on sequential inputs where a partial information may be available on each frame. ")))),i.a.createElement("div",{className:"resume-date text-md-right"},i.a.createElement("span",{className:"text-primary"},"2018 - Present"))),i.a.createElement("div",{className:"resume-item d-flex flex-column flex-md-row justify-content-between mb-5"},i.a.createElement("div",{className:"resume-content"},i.a.createElement("h3",{className:"mb-0"},"Teaching Assistant, Deep Learning"),i.a.createElement("div",{className:"subheading mb-3"},"Vanderbilt University: Nashville, TN"),i.a.createElement("p",null,"Experience teaching and communicating with students through weekly help sessions and replacing the professor when needed.")),i.a.createElement("div",{className:"resume-date text-md-right"},i.a.createElement("span",{className:"text-primary"},"2016 â 2017"))),i.a.createElement("div",{className:"resume-item d-flex flex-column flex-md-row justify-content-between mb-5"},i.a.createElement("div",{className:"resume-content"},i.a.createElement("h3",{className:"mb-0"},"Research Assistant, Biomedical Engineering"),i.a.createElement("div",{className:"subheading mb-3"},"The City College of New York: New York City, NY"),i.a.createElement("p",null,i.a.createElement("ul",null,i.a.createElement("li",null,"Designed and built a cost efficient electromyograph computer interface that supports 44 channels and connects to a computer over USB to be used on a robotic arm for amputees"),i.a.createElement("li",null,"Applied learning algorithms to make the prosthetic adapt to each userâs muscle electrical signals.")))),i.a.createElement("div",{className:"resume-date text-md-right"},i.a.createElement("span",{className:"text-primary"},"2015"))),i.a.createElement("div",{className:"resume-item d-flex flex-column flex-md-row justify-content-between mb-5"},i.a.createElement("div",{className:"resume-content"},i.a.createElement("h3",{className:"mb-0"},"Undergrad Research"),i.a.createElement("div",{className:"subheading mb-3"},"University of Patras: Patras, Greece"),i.a.createElement("p",null,i.a.createElement("ul",null,i.a.createElement("li",null,"Designed and built a portable, non-contact ECG device intended as a low-cost, continuous monitoring solution for persons at risk of cardiac problems. (Diploma Thesis)"),i.a.createElement("li",null,"Motion analysis of robotic swarm formations cooperating for a common goal."),i.a.createElement("li",null,"Literature research on pattern recognition methods for detection of forgery in paintings.")))))))}function x(){return i.a.createElement("section",{className:"resume-section p-3 p-lg-5 d-flex align-items-center",id:"skills"},i.a.createElement("div",{className:"w-100"},i.a.createElement("h2",{className:"mb-5"},"Skills"),i.a.createElement("div",{className:"subheading mb-3"},"Platforms & Suites"),i.a.createElement("p",null,i.a.createElement("ul",null,i.a.createElement("li",null,"Linux"),i.a.createElement("li",null,"Windows"),i.a.createElement("li",null,"Docker"),i.a.createElement("li",null,"RTOS"),i.a.createElement("li",null,"Embedded Systems"),i.a.createElement("li",null,"Simulation Environmets"))),i.a.createElement("div",{className:"subheading mb-3"},"Programming Languages & Tools"),i.a.createElement("p",null,i.a.createElement("ul",null,i.a.createElement("li",null,"Python"),i.a.createElement("li",null,"Matlab"),i.a.createElement("li",null,"C++"),i.a.createElement("li",null,"C"),i.a.createElement("li",null,"Latex"))),i.a.createElement("div",{className:"subheading mb-3"},"Workflow"),i.a.createElement("p",null,i.a.createElement("ul",null,i.a.createElement("li",null,"Git"),i.a.createElement("li",null,"Tensorflow"),i.a.createElement("li",null,"Keras"),i.a.createElement("li",null,"Sklearn"),i.a.createElement("li",null,"Simulink")))))}function k(){return i.a.createElement("section",{className:"resume-section p-3 p-lg-5 d-flex align-items-center",id:"awards"},i.a.createElement("div",{className:"w-100"},i.a.createElement("h2",{className:"mb-5"},"Awards"),i.a.createElement("ul",{className:"fa-ul mb-0"},i.a.createElement("li",null,i.a.createElement("i",{className:"fa-li fa fa-trophy text-warning"}),"Best Paper Award at the Workshop for Assured Autonomous Systems (WAAS), which was part of the IEEE Security & Privacy Conference (2020)"),i.a.createElement("li",null,i.a.createElement("i",{className:"fa-li fa fa-trophy text-warning"}),"4",i.a.createElement("sup",null,"th"),"Place in the 22nd National Olympiad in Computer Science"))))}function S(){return i.a.createElement("section",{className:"resume-section p-3 p-lg-5 d-flex align-items-center",id:"publications"},i.a.createElement("div",{className:"w-100"},i.a.createElement("h2",{className:"mb-5"},"Publications"),i.a.createElement("ul",{className:"fa-ul mb-0"},i.a.createElement("li",null,i.a.createElement("i",{className:"fa-li fa fa-graduation-cap"}),"Assurance Monitoring of Cyber-Physical Systems with Machine Learning Components - ",i.a.createElement("a",{href:"https://arxiv.org/abs/2001.05014",target:"_blank",rel:"noopener noreferrer"},"arXiv"),i.a.createElement("br",null),"Tools and Methods of Competitive Engineering Symposium (TMCE 2020) - Dublin, Ireland"),i.a.createElement("li",null,i.a.createElement("i",{className:"fa-li fa fa-graduation-cap"}),"Trusted Confidence Bounds for Learning Enabled Cyber-Physical Systems - ",i.a.createElement("a",{href:"https://arxiv.org/abs/2003.05107",target:"_blank",rel:"noopener noreferrer"},"arXiv"),i.a.createElement("br",null),"Workshop on Assured Autonomous Systems (WAAS 2020) - Best Paper Award ",i.a.createElement("br",null),"41",i.a.createElement("sup",null,"st")," IEEE Symposium on Security and Privacy - San Francisco, CA"),i.a.createElement("li",null,i.a.createElement("i",{className:"fa-li fa fa-graduation-cap"}),"Improving Prediction Confidence in Learning-Enabled Autonomous Systems",i.a.createElement("br",null),"In International Conference on Dynamic Data Driven Application Systems (pp. 217-224). Springer"))))}a("on1w");var _=a("i/sI"),C=a.n(_),T=a("/tX2"),P=a.n(T),I=a("V7ms"),j=a.n(I),A=a("lJ2V"),D=a.n(A),O=a("sbnl"),q=a.n(O),L=a("EuHx"),B=a.n(L),M=a("obI2"),R=a.n(M),W=a("kVU1"),V=a.n(W),Y=a("fbAu"),F=a.n(Y),H=a("Yrzv"),X=a.n(H),U=a("WSgm"),z=a.n(U),J=a("LbtI"),K=a.n(J),G=a("IwmZ"),Z=a.n(G);function Q(){return i.a.createElement("section",{className:"resume-section p-3 p-lg-5 d-flex justify-content-center",id:"research"},i.a.createElement("div",{className:"w-100"},i.a.createElement("h2",{className:"mb-5"},"Practical Applications"),i.a.createElement("div",{className:"resume-item d-flex flex-column flex-md-row justify-content-between mb-5"},i.a.createElement("div",{className:"resume-content"},i.a.createElement("h3",{className:"mb-2"},"Assurance Monitoring for Cyber-physical Systems"),i.a.createElement("h5",{className:"mb-0"},"What is a cyber-physical system? "),i.a.createElement("p",{className:"mb-3"},i.a.createElement("img",{src:C.a,class:"rounded float-right research_image_portrait",alt:""}),"Cyber-Phsyical Systems (CPS) integrate sensing, computation and networking which are parts of physical processes and are monitored or controlled using computer algorithms. In CPS physical and software components are deeply intertwined. Many modern products in major industrial sectors, such as:",i.a.createElement("ul",null,i.a.createElement("li",null,"Automotive"),i.a.createElement("li",null,"Avionics"),i.a.createElement("li",null,"Medical Devices"),i.a.createElement("li",null,"Power Systems"),i.a.createElement("li",null,"Smart Cities")),"already are or rapidly becoming CPS driven by new requirements and competitive pressures. These are safety critical fields where the introduction of autonomous components are challenging as potential incorrect decisions can have very serious consequences. For such components to safely be integrated in CPS they need to be complemented by methods and practices that will assure the safe operation of the system."),i.a.createElement("h5",{className:"mb-0"},"Machine Learning and Challenges "),i.a.createElement("p",{className:"mb-2"},"Semi-autonomous and autonomous vehicles are a very significant domain and opportunity for CPS. Modern vehicles are equipped with a number of sensors, like cameras and Light Detection and Ranging (LiDAR) sensors, to either achieve fully autonomous driving or assist the human operator in dangerous scenarios. Even though all these sensors produce a lot of information about the environment and the surroundings of the vehicle, it can be challenging and tedious to have some desired control actions for all possible scenarios on continuously changing environments. This shows the need for integrating machine learning components in CPS that can deal with decision-making in dynamic environments."),i.a.createElement("p",{className:"mb-2"},"The most commonly used machine learning component is the Deep Neural Networks (DNN) because of their high knowledge capacity and their ability to receive and make decisions for high-dimensional inputs. They achieve this by transforming the inputs to a number of sequential feature layers of less-and-less abstraction until a classifier can be defined in a lower dimensional feature space. The mapping between the different feature layers is learned using labeled training data and the knowledge of a particular DNN model is stored in its weight parameters. Modern architectures can have hundreds of layers and are parameterized using millions of values. This makes it challenging for DNNs to be used in safety critical CPS application because its hard to understand how a DNN makes a particular decision, or reason about a decision, and how confident a decision is. This problem with DNNs is also called ",i.a.createElement("em",null,"non transparency"),". DNNs commonly use a ",i.a.createElement("em",null,"softmax")," layer to provide probability-like outputs, meaning the output for each class is in [0,1] and the sum of the outputs of all possible classes is 1. However, these probabilities are typically overconfident even for inputs coming from the same distribution as the training data and they cannot be used as reliable confidence measures."),i.a.createElement("p",{className:"mb-2"},"Deploying a CPS with machine learning components in the real world comes with challenges that are hard to foresee in design-time. CPS usually operate in highly dynamic environments where unknown scenarios may appear. Even using very deep DNN architectures it is hard to have training data for every possible input a system may face during testing. The unpredictability in the real world will force the system to work under different conditions. For example, an autonomous vehicle has to drive safely in different weather conditions. Different operating conditions may introduce different kind of noise into the input data that will make confident decisions harder."),i.a.createElement("p",{className:"mb-3"},i.a.createElement("strong",null,"Problems we consider are:"),i.a.createElement("ul",null,i.a.createElement("li",null,"How do we compute well-calibrated confidence metrics with each decision made by a machine learning for effective integration in CPS?"),i.a.createElement("li",null,"How to minimize the human intervention and maximize the safe operation time?"),i.a.createElement("li",null,"How to process and take confident decisions on high-dimensional data?"))),i.a.createElement("h5",{className:"mb-0"},"Research Contributions "),i.a.createElement("p",{className:"mb-2"},i.a.createElement("img",{src:j.a,class:"rounded float-right research_image_landscape",alt:""}),"Our objective is to complement the prediction of DNNs with a computation of confidence. We consider DNNs used for classification in CPS. In addition to the class prediction, we compute prediction sets of classes that are guaranteed to include the correct class with the desired significance level. We focus on computationally efficient algorithms that can be used for real-time monitoring. An efficient and robust approach must ensure a small and well-calibrated error rate while limiting the number of alarms. This enables the design of monitors which can ensure a bounded small error rate while limiting the number of inputs for which an accurate prediction cannot be made."),i.a.createElement("p",{className:"mb-2"},i.a.createElement("img",{src:P.a,class:"rounded float-right research_image_landscape",alt:""}),"We propose the transformation of the high-dimensional inputs into lower-dimensional embedding representations that can be handled efficiently by the assurance monitor. For these representations to be used for monitoring they need to be in a form in which similarity between different data points can be defined. We use distance metric learning techniques to compute embedding representations such that the euclidean distance between them is a metric of similarity between the original inputs. Moreover, autonomous systems are desirable to operate safely for as long as possible and require as little intervention by humans as possible. We propose an optimization method to minimize the instances where a confident decision cannot be made for a given input. This work has been implemented and evaluated."),i.a.createElement("p",{className:"mb-2"},i.a.createElement("img",{src:D.a,class:"rounded float-right research_image_landscape",alt:""}),"In CPS, it is not only important to have predictions with well-calibrated confidence but also to be able to choose the desired significance level based on the application requirements. ICP computes a prediction set Î",i.a.createElement("sup",null,"Îµ")," with a chosen significance level Îµ and Î",i.a.createElement("sup",null,"Îµ")," may include any subset of all possible classes. Even though reducing the number of possible classes may be helpful when the information is provide to a human, in an autonomous system it is desirable that the prediction is unique, i.e., |Î",i.a.createElement("sup",null,"Îµ"),"|=1. Therefore, we assume that set predictions that contain multiple classes, i.e., |Î",i.a.createElement("sup",null,"Îµ"),"| > 1, lead to a rejection of the input and require human intervention. For this reason, it is desirable to minimize the number of test inputs with multiple predictions. If the set Î",i.a.createElement("sup",null,"Îµ")," contains a single prediction, the monitor outputs ",i.a.createElement("em",null,"out = 1")," to indicate a confident prediction with well-calibrated error rate Îµ. If the predicted set contains multiple predictions, the monitor rejects the prediction and raises an alarm. Finally, if the predicted set is empty the monitor outputs ",i.a.createElement("em",null,"out = 0")," to indicate that no label is probable. We distinguish between multiple and no predictions, because they may lead to different action in the system. For example, no prediction may be the result of out-of-distribution inputs while multiple possible predictions may be an indication that the significance level is smaller than the accuracy of the underlying DNN. Choosing a relatively small significance level that can consistently produce prediction sets with only one class is important. To do this, we apply ICP on the data in the calibration/validation set and compute the smallest significance level Îµ that does not produce any prediction set with |Î",i.a.createElement("sup",null,"Îµ"),"|>1. Assuming the distribution of the test set is the same as the one of the calibration/validation set we expect the same value of Îµ to minimize the prediction sets with multiple classes on the test data. The top figure shows an illustration for the assurance monitoring algorithm with a traffic sign recognition example. The left side of the figure shows the image of a 60km/h speed limit sign. Our assurance monitor is used with different significance level Îµ choices to generate sets of possible predicted labels. When Îµ â [0.001,0.004), the possible labels are 'Speed limit 50km/h', 'Speed limit 60km/h', 'Speed limit 80km/h'; when Îµ â [0.004,0.006), the possible labels are 'Speed limit 50km/h', 'Speed limit 60km/h'; and finally when Îµ â [0.006,0.0124], the algorithm produces a single prediction 'Speed limit 60km/h' which is obviously correct."),i.a.createElement("p",{className:"mb-2"},i.a.createElement("img",{src:q.a,class:"rounded float-right research_image_landscape",alt:""}),"The plot on the right shows results regarding calibration and efficiency of our assurnce monitor on traffic sign recognition. The performance curve, plotted with blue color, indicates the percentage of traffic signs for which our assurance monitor had to produce prediction sets with more than one class to satisfy the chosen significance level. We see that the optimal significance level to avoid prediction sets with multiple classes is 0.037. The calibration curve, plotted with orange color, indicates the percentage of errors, meaning the percentage of traffic signs for which the correct class was not included in the prediction set, for a chosen significance level. The curve is linear and bounds the error rate across all the Îµ values, signs of a well-calibrated assurance monitor."),i.a.createElement("h5",{className:"mb-0"},"Dealing with sequencies of data"),i.a.createElement("p",{className:"mb-2"},"Autonomous systems are equipped with sensors to observe the environment and take control decisions. Such systems can benefit from methods that allow to improve prediction and decision making through a feedback loop that queries the sensor inputs when more information is needed. Such a paradigm has been used in a variety of applications such as multimedia context assessment, aerial vehicle tracking, automatic target recognition, self-aware aerospace vehicles, and smart cities."),i.a.createElement("p",{className:"mb-2"},"In particular, autonomous systems can utilize perception learning-enabled components (LECs) to observe the environment and make predictions used for decision making and control. LECs such as deep neural networks (DNNs) can generalize well on test data that come from the same distribution as the training data and their predictions can be trusted. However, during the system operation the input data may be different than the training data resulting to large prediction errors. An approach to address this challenge is to quantify the uncertainty of the prediction and query the sensors for additional inputs in order to improve the confidence of the prediction. The approach must be computationally efficient so it can be executed in real-time for closing the loop with the system."),i.a.createElement("img",{src:B.a,class:"rounded float-center research_image_landscape_large",alt:""}),i.a.createElement("p",{className:"mb-2"},"We designed a feedback loop design between LECs used for classification and the sensors of an autonomous system in order to improve the confidence of the predictions. We design a classifier using ICP based on a triplet network architecture in order to learn representations that can be used to quantify the similarity between test and training examples. Given a significance level, the method allows computing confident set predictions. A feedback loop that queries the sensors for a new input, as shown in the figure above, is used to further refine the predictions and increase the classification accuracy. The method is computationally efficient, scalable to high-dimensional inputs, and can be executed in a feedback loop with the system in real-time. The approach is evaluated using a traffic sign recognition dataset and the initial results show that the error rate is reduced."),i.a.createElement("p",{className:"mb-2"},i.a.createElement("img",{src:R.a,class:"rounded float-center research_image_landscape_large",alt:""}),"Predictions made by ICP are efficient and well-calibrated when the training and test data satisfy the randomness and exchangeability assumptions. This is not the case when the data are part of sequences. Such example is the traffic sign recognition by an autonomous vehicle while it approaches a sign as we see in the figure above. Each input belonging in a sequence is related to previous inputs and they are not independent and identically distributed (IID)."),i.a.createElement("p",{className:"mb-2"},i.a.createElement("img",{src:V.a,class:"rounded float-right research_image_landscape_2",alt:""}),"In our work we observed that it is more likely for an incorrect prediction to happen in the beginning of the sequences when the sign is far. This is illustrated in the plot on the right. To avoid such incorrect classifications, in our method the final decision is made only after ",i.a.createElement("em",null,"k")," consecutive identical predictions. The parameter ",i.a.createElement("em",null,"k")," represents a trade-off between robustness and decision time, as larger ",i.a.createElement("em",null,"k")," leads to additional delay but more confident decisions. Further, very low ",i.a.createElement("em",null,"k")," values may lead to incorrect decisions while very large values may not allow a timely a decision. Our results below, demonstrate that utilizing the feedback-loop with the additional parameter ",i.a.createElement("em",null,"k")," can lower the error-rate for any chosen significance level when the inputs are sequential. We also show the effect of the parameter ",i.a.createElement("em",null,"k")," in the time required for a confident prediction."),i.a.createElement("img",{src:F.a,class:"rounded float-left research_image_landscape_sidebyside",alt:""}),i.a.createElement("img",{src:X.a,class:"rounded float-center research_image_landscape_sidebyside mb-4",alt:""}),i.a.createElement("h5",{className:"mb-0"},"Assurance monitors and object detection "),i.a.createElement("p",{className:"mb-2"},"Cyber-Physical systems (CPS) take control decisions based on various information from the surrounding environment which is detected by different sensors. The complexity of the environments in which modern CPS operate has made the use of Learning Enabled Components (LECs) essential. However, the integration of components, such us DNNs, in safety-critical CPS is not easy because of the lack of transparency and their inability to reason for their decisions. Machine learning (ML) techniques are known to be more robust in their training space but cannot extrapolate beyond that. For a CPS, like an autonomous vehicle, this property means that the safe operation can only be expected when the surrounding environment is very similar to the environments that were used for training and the controller may not be able to produce safe commands in the presence of unseen sensor inputs. The task of covering all possible operational conditions would be very tedious, impractical and highly impossible because of the unexpected nature of human behavior. However, at any given sensor input, there is only a limited number of objects that affect the control commands, such as the position of other vehicles, traffic signs pedestrians etc."),i.a.createElement("p",{className:"mb-2"},"The goal of the state-of-the-art object detection methods is twofold. Detect regions in images where an object that belong to a number of predefined classes exists and determine the class that the object belongs too. The region detection problem is to find a bounded-box that will enclose an object of interest as accurately as possible. Most of the recent methods based on deep neural networks solve approach the solution to this as a regression problem. On the other hand, determining the class of an object is a classification problem. Most of the object detection methods use a softmax layer to produce probability-like scores as a measure of confidence that an object belong to each of the possible classes. However the probabilities produced by the softmax layer tend to be poorly calibrated and often higher than the actual posterior probability that the prediction is correct."),i.a.createElement("img",{src:z.a,class:"rounded float-center research_image_landscape_large",alt:""}),i.a.createElement("p",{className:"mb-2"},"We worked on a method to improve the confidence estimation on the classification of the objects in the computed bounded boxes based on ICP. Our previous work using ICP to compute well-calibrated confidence measures on image classification shows that it is possible to bound the expected error-rate accurately. A natural extension is for this method to be used to complement and improve the calibration of object detection methods. The figure above shows the design time steps required for this method. The required data to train DNN models for object detection include bounded boxes that show the position of an object in the whole frame as well as the class of the marked object. In our experiments and published work we show that ICP does not perform well when the input data are high-dimensional like in the case of RGB images. To deal with this we propose the mapping of the original inputs to appropriate low-dimensional embedding representation. These representations belong in a space where the euclidean distance between image representations is a metric of similarity between the input themselves. The embedding representations can be produced by training DNNs with methods like ",i.a.createElement("em",null,"triplet")," and ",i.a.createElement("em",null,"siamese")," networks. The available training images are split into the proper training set and the calibration set. In order to train a DNN to compute the embedding representations the first requirement is to isolate the objects of interest from all the proper training set images and use them by themselves as inputs with their ground-truth classes. The object detection network is trained using the images in the proper training set to compute the region and class of each existing object in the image. The two models, one for the embedding representation computation and one for the object detection do not have any dependency on each other, other that being trained using the same dataset, and can be trained in parallel. Each object of interest in the calibration set is also being cropped and used to compute the nonconformity (NC) scores as required by the ICP framework."),i.a.createElement("img",{src:K.a,class:"rounded float-center research_image_landscape_large",alt:""}),i.a.createElement("p",{className:"mb-2"},'This figure illustrates the pipeline we designed to compute a prediction set for each detected object. First, the trained object detection model is used to enclose the detected objects in bounded boxes and classify them in one of the possible classes. The image content inside each bounded box is then mapped into a lower-dimensional embedding representation using a siamese or a triplet network. The ICP framework is used to compute prediction sets that include the correct class with a desired confidence/significance level. ICP computes p-values associated to each possible class by estimating how non conformal, or "strange", an input-label pair is compared to other such pairs in the proper training set using a NC function. Depending on the choice of the NC function ICP may require access to the embedding representations of all the available data in the proper training set or metrics extracted from these data such as the centroids of each class in the embedding space. In the figure below we show how our approach works in driving scenario. For each detected object our assurance monitor creates prediction sets that will include the true class with a significance level 0.05.'),i.a.createElement("img",{src:Z.a,class:"rounded float-center research_image_landscape_large",alt:""})))))}t.default=function(){return i.a.createElement(o.a,null,i.a.createElement(g,null),i.a.createElement("div",{className:"container-fluid p-0"},i.a.createElement(E,null),i.a.createElement("hr",{className:"m-0"}),i.a.createElement(w,null),i.a.createElement("hr",{className:"m-0"}),i.a.createElement(N,null),i.a.createElement("hr",{className:"m-0"}),i.a.createElement(x,null),i.a.createElement("hr",{className:"m-0"}),i.a.createElement(k,null),i.a.createElement("hr",{className:"m-0"}),i.a.createElement(S,null),i.a.createElement("hr",{className:"m-0"}),i.a.createElement(Q,null)),i.a.createElement("div",{className:"print-footer"},i.a.createElement("h5",null,b.a.firstName,i.a.createElement("span",{className:"text-primary"},b.a.lastName)," Â· ",b.a.phone)))}},SksO:function(e,t){function a(t,n){return e.exports=a=Object.setPrototypeOf||function(e,t){return e.__proto__=t,e},a(t,n)}e.exports=a},TSYQ:function(e,t,a){var n;a("LK8F"),function(){"use strict";var a={}.hasOwnProperty;function i(){for(var e=[],t=0;t<arguments.length;t++){var n=arguments[t];if(n){var o=typeof n;if("string"===o||"number"===o)e.push(n);else if(Array.isArray(n)&&n.length){var s=i.apply(null,n);s&&e.push(s)}else if("object"===o)for(var r in n)a.call(n,r)&&n[r]&&e.push(r)}}return e.join(" ")}e.exports?(i.default=i,e.exports=i):void 0===(n=function(){return i}.apply(t,[]))||(e.exports=n)}()},V7ms:function(e,t,a){e.exports=a.p+"static/approach-27ce6ce9ca2aca6dfbda50fe32570ccf.png"},W8MJ:function(e,t){function a(e,t){for(var a=0;a<t.length;a++){var n=t[a];n.enumerable=n.enumerable||!1,n.configurable=!0,"value"in n&&(n.writable=!0),Object.defineProperty(e,n.key,n)}}e.exports=function(e,t,n){return t&&a(e.prototype,t),n&&a(e,n),e}},WSgm:function(e,t,a){e.exports=a.p+"static/object_detection_distance_learning-353f0068c235d10254bd4c769868456b.svg"},WkPL:function(e,t){e.exports=function(e,t){(null==t||t>e.length)&&(t=e.length);for(var a=0,n=new Array(t);a<t;a++)n[a]=e[a];return n}},YIkO:function(e,t,a){"use strict";a("V+eJ"),a("dZ+Y"),a("bWfx"),a("2Spj"),a("LK8F"),a("HAE/");var n=a("TqRt");Object.defineProperty(t,"__esModule",{value:!0}),t.default=void 0;var i=n(a("pVnL")),o=n(a("lSNA")),s=n(a("RIqP")),r=n(a("lwsE")),l=n(a("a1gu")),c=n(a("Nsbk")),m=n(a("PJYZ")),d=n(a("W8MJ")),u=n(a("7W2i")),h=n(a("17x9")),p=n(a("q1tI")),f=n(a("TSYQ")),b=n(a("Fxm3"));var g=function(e){function t(e){var a;return(0,r.default)(this,t),(a=(0,l.default)(this,(0,c.default)(t).call(this,e))).state={targetItems:[],inViewState:[],isScrolledPast:[]},a._handleSpy=a._handleSpy.bind((0,m.default)(a)),a}return(0,u.default)(t,e),(0,d.default)(t,null,[{key:"propTypes",get:function(){return{items:h.default.arrayOf(h.default.string).isRequired,currentClassName:h.default.string.isRequired,scrolledPastClassName:h.default.string,style:h.default.object,componentTag:h.default.oneOfType([h.default.string,h.default.element]),offset:h.default.number,rootEl:h.default.string,onUpdate:h.default.func}}},{key:"defaultProps",get:function(){return{items:[],currentClassName:"",style:{},componentTag:"ul",offset:0,onUpdate:function(){}}}}]),(0,d.default)(t,[{key:"_initSpyTarget",value:function(e){return e.map((function(e){return document.getElementById(e)}))}},{key:"_fillArray",value:function(e,t){for(var a=[],n=0,i=e.length;n<i;n++)a[n]=t;return a}},{key:"_isScrolled",value:function(){return this._getScrollDimension().scrollTop>0}},{key:"_getScrollDimension",value:function(){var e=document,t=this.props.rootEl;return{scrollTop:t?e.querySelector(t).scrollTop:e.documentElement.scrollTop||e.body.parentNode.scrollTop||e.body.scrollTop,scrollHeight:t?e.querySelector(t).scrollHeight:e.documentElement.scrollHeight||e.body.parentNode.scrollHeight||e.body.scrollHeight}}},{key:"_getElemsViewState",value:function(e){for(var t=[],a=[],n=[],i=e||this.state.targetItems,o=!1,r=0,l=i.length;r<l;r++){var c=i[r],m=!o&&this._isInView(c);m?(o=!0,t.push(c)):a.push(c);var d=r===l-1,u=this._isScrolled();this._isAtBottom()&&this._isInView(c)&&!m&&d&&u&&(a.pop(),a.push.apply(a,(0,s.default)(t)),t=[c],n=this._fillArray(n,!1),m=!0),n.push(m)}return{inView:t,outView:a,viewStatusList:n,scrolledPast:this.props.scrolledPastClassName&&this._getScrolledPast(n)}}},{key:"_isInView",value:function(e){if(!e)return!1;var t,a=this.props,n=a.rootEl,i=a.offset;n&&(t=document.querySelector(n).getBoundingClientRect());var o=e.getBoundingClientRect(),s=n?t.height:window.innerHeight,r=this._getScrollDimension().scrollTop,l=r+s,c=n?o.top+r-t.top+i:o.top+r+i,m=c+e.offsetHeight;return c<l&&m>r}},{key:"_isAtBottom",value:function(){var e=this.props.rootEl,t=this._getScrollDimension(),a=t.scrollTop,n=t.scrollHeight;return a+(e?document.querySelector(e).getBoundingClientRect().height:window.innerHeight)>=n}},{key:"_getScrolledPast",value:function(e){if(!e.some((function(e){return e})))return e;var t=!1;return e.map((function(e){return e&&!t?(t=!0,!1):!t}))}},{key:"_spy",value:function(e){var t=this,a=this._getElemsViewState(e),n=this.state.inViewState;this.setState({inViewState:a.viewStatusList,isScrolledPast:a.scrolledPast},(function(){t._update(n)}))}},{key:"_update",value:function(e){var t,a;(t=this.state.inViewState,a=e,t.length===a.length&&t.every((function(e,t){return e===a[t]})))||this.props.onUpdate(this.state.targetItems[this.state.inViewState.indexOf(!0)])}},{key:"_handleSpy",value:function(){(0,b.default)(this._spy(),100)}},{key:"_initFromProps",value:function(){var e=this._initSpyTarget(this.props.items);this.setState({targetItems:e}),this._spy(e)}},{key:"offEvent",value:function(){(this.props.rootEl?document.querySelector(this.props.rootEl):window).removeEventListener("scroll",this._handleSpy)}},{key:"onEvent",value:function(){(this.props.rootEl?document.querySelector(this.props.rootEl):window).addEventListener("scroll",this._handleSpy)}},{key:"componentDidMount",value:function(){this._initFromProps(),this.onEvent()}},{key:"componentWillUnmount",value:function(){this.offEvent()}},{key:"UNSAFE_componentWillReceiveProps",value:function(){this._initFromProps()}},{key:"render",value:function(){var e=this,t=this.props.componentTag,a=this.props,n=a.children,s=a.className,r=a.scrolledPastClassName,l=a.style,c=0,m=p.default.Children.map(n,(function(t,a){var n;if(!t)return null;var s=t.type,l=r&&e.state.isScrolledPast[a],m=(0,f.default)((n={},(0,o.default)(n,"".concat(t.props.className),t.props.className),(0,o.default)(n,"".concat(e.props.currentClassName),e.state.inViewState[a]),(0,o.default)(n,"".concat(e.props.scrolledPastClassName),l),n));return p.default.createElement(s,(0,i.default)({},t.props,{className:m,key:c++}),t.props.children)})),d=(0,f.default)((0,o.default)({},"".concat(s),s));return p.default.createElement(t,{className:d,style:l},m)}}]),t}(p.default.Component);t.default=g},Yrzv:function(e,t,a){e.exports=a.p+"static/delay_plot-37040c0aba1955933b6623c634ae15d5.png"},ZhPi:function(e,t,a){var n=a("WkPL");e.exports=function(e,t){if(e){if("string"==typeof e)return n(e,t);var a=Object.prototype.toString.call(e).slice(8,-1);return"Object"===a&&e.constructor&&(a=e.constructor.name),"Map"===a||"Set"===a?Array.from(e):"Arguments"===a||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(a)?n(e,t):void 0}}},a1gu:function(e,t,a){var n=a("cDf5"),i=a("PJYZ");e.exports=function(e,t){return!t||"object"!==n(t)&&"function"!=typeof t?i(e):t}},"d/Oy":function(e,t,a){e.exports=a.p+"static/DimitriosBoursinosResume-62063f1b1900919e06c15d0425f6826d.pdf"},dwco:function(e,t,a){a("Oyvg"),a("eM6i"),a("2Spj"),function(){"use strict";e.exports={polyfill:function(){var e=window,t=document;if(!("scrollBehavior"in t.documentElement.style)||!0===e.__forceSmoothScrollPolyfill__){var a,n=e.HTMLElement||e.Element,i={scroll:e.scroll||e.scrollTo,scrollBy:e.scrollBy,elementScroll:n.prototype.scroll||r,scrollIntoView:n.prototype.scrollIntoView},o=e.performance&&e.performance.now?e.performance.now.bind(e.performance):Date.now,s=(a=e.navigator.userAgent,new RegExp(["MSIE ","Trident/","Edge/"].join("|")).test(a)?1:0);e.scroll=e.scrollTo=function(){void 0!==arguments[0]&&(!0!==l(arguments[0])?p.call(e,t.body,void 0!==arguments[0].left?~~arguments[0].left:e.scrollX||e.pageXOffset,void 0!==arguments[0].top?~~arguments[0].top:e.scrollY||e.pageYOffset):i.scroll.call(e,void 0!==arguments[0].left?arguments[0].left:"object"!=typeof arguments[0]?arguments[0]:e.scrollX||e.pageXOffset,void 0!==arguments[0].top?arguments[0].top:void 0!==arguments[1]?arguments[1]:e.scrollY||e.pageYOffset))},e.scrollBy=function(){void 0!==arguments[0]&&(l(arguments[0])?i.scrollBy.call(e,void 0!==arguments[0].left?arguments[0].left:"object"!=typeof arguments[0]?arguments[0]:0,void 0!==arguments[0].top?arguments[0].top:void 0!==arguments[1]?arguments[1]:0):p.call(e,t.body,~~arguments[0].left+(e.scrollX||e.pageXOffset),~~arguments[0].top+(e.scrollY||e.pageYOffset)))},n.prototype.scroll=n.prototype.scrollTo=function(){if(void 0!==arguments[0])if(!0!==l(arguments[0])){var e=arguments[0].left,t=arguments[0].top;p.call(this,this,void 0===e?this.scrollLeft:~~e,void 0===t?this.scrollTop:~~t)}else{if("number"==typeof arguments[0]&&void 0===arguments[1])throw new SyntaxError("Value could not be converted");i.elementScroll.call(this,void 0!==arguments[0].left?~~arguments[0].left:"object"!=typeof arguments[0]?~~arguments[0]:this.scrollLeft,void 0!==arguments[0].top?~~arguments[0].top:void 0!==arguments[1]?~~arguments[1]:this.scrollTop)}},n.prototype.scrollBy=function(){void 0!==arguments[0]&&(!0!==l(arguments[0])?this.scroll({left:~~arguments[0].left+this.scrollLeft,top:~~arguments[0].top+this.scrollTop,behavior:arguments[0].behavior}):i.elementScroll.call(this,void 0!==arguments[0].left?~~arguments[0].left+this.scrollLeft:~~arguments[0]+this.scrollLeft,void 0!==arguments[0].top?~~arguments[0].top+this.scrollTop:~~arguments[1]+this.scrollTop))},n.prototype.scrollIntoView=function(){if(!0!==l(arguments[0])){var a=u(this),n=a.getBoundingClientRect(),o=this.getBoundingClientRect();a!==t.body?(p.call(this,a,a.scrollLeft+o.left-n.left,a.scrollTop+o.top-n.top),"fixed"!==e.getComputedStyle(a).position&&e.scrollBy({left:n.left,top:n.top,behavior:"smooth"})):e.scrollBy({left:o.left,top:o.top,behavior:"smooth"})}else i.scrollIntoView.call(this,void 0===arguments[0]||arguments[0])}}function r(e,t){this.scrollLeft=e,this.scrollTop=t}function l(e){if(null===e||"object"!=typeof e||void 0===e.behavior||"auto"===e.behavior||"instant"===e.behavior)return!0;if("object"==typeof e&&"smooth"===e.behavior)return!1;throw new TypeError("behavior member of ScrollOptions "+e.behavior+" is not a valid value for enumeration ScrollBehavior.")}function c(e,t){return"Y"===t?e.clientHeight+s<e.scrollHeight:"X"===t?e.clientWidth+s<e.scrollWidth:void 0}function m(t,a){var n=e.getComputedStyle(t,null)["overflow"+a];return"auto"===n||"scroll"===n}function d(e){var t=c(e,"Y")&&m(e,"Y"),a=c(e,"X")&&m(e,"X");return t||a}function u(e){for(;e!==t.body&&!1===d(e);)e=e.parentNode||e.host;return e}function h(t){var a,n,i,s,r=(o()-t.startTime)/468;s=r=r>1?1:r,a=.5*(1-Math.cos(Math.PI*s)),n=t.startX+(t.x-t.startX)*a,i=t.startY+(t.y-t.startY)*a,t.method.call(t.scrollable,n,i),n===t.x&&i===t.y||e.requestAnimationFrame(h.bind(e,t))}function p(a,n,s){var l,c,m,d,u=o();a===t.body?(l=e,c=e.scrollX||e.pageXOffset,m=e.scrollY||e.pageYOffset,d=i.scroll):(l=a,c=a.scrollLeft,m=a.scrollTop,d=r),h({scrollable:l,method:d,startTime:u,startX:c,startY:m,x:n,y:s})}}}}()},fbAu:function(e,t,a){e.exports=a.p+"static/calibration_plot-4e29823db80474a762c4d3e1f22a3df2.png"},"i/sI":function(e,t,a){e.exports=a.p+"static/cps_example-0dd64f068501d9422aa27fcf869946a8.jpg"},kVU1:function(e,t,a){e.exports=a.p+"static/error_frames-bfcb466646b3d23566cc811286768dfd.png"},ku9C:function(e,t,a){e.exports=a.p+"static/avatar-0f9d40d68d4bece705dc8130b2ed32ee.jpg"},lJ2V:function(e,t,a){e.exports=a.p+"static/significance_level_figure-2155935bb626e739ee3e2ae0b8282a66.png"},lSNA:function(e,t){e.exports=function(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}},lwsE:function(e,t){e.exports=function(e,t){if(!(e instanceof t))throw new TypeError("Cannot call a class as a function")}},obI2:function(e,t,a){e.exports=a.p+"static/sign_time-5ee97488761e8c097a2250bfd0424fbb.svg"},obyI:function(e,t){e.exports={siteTitle:"Dimitrios Boursinos",manifestName:"Resume",manifestShortName:"Landing",manifestStartUrl:"/",manifestBackgroundColor:"#4717F6",manifestThemeColor:"#4717F6",manifestDisplay:"standalone",manifestIcon:"src/assets/img/website-icon.png",pathPrefix:"/",firstName:"Dimitrios",lastName:"Boursinos",socialLinks:[{icon:"fa-github",name:"Github",url:"https://github.com/xxxxxxxxxx"},{icon:"fa-linkedin-in",name:"Linkedin",url:"https://www.linkedin.com/in/xxxxxxxxxx/"},{icon:"fa-twitter",name:"Twitter",url:"https://twitter.com/xxxxxxxx"},{icon:"fa-facebook-f",name:"Facebook",url:"https://www.facebook.com/xxxxxxxx"}],email:"dimitris.boursinos@gmail.com",phone:"âª615.668.0574â¬",address:"Nashville, TN"}},on1w:function(e,t,a){},sbnl:function(e,t,a){e.exports=a.p+"static/compute_epsilon-52409faa60681f3f5d03ff48e6315df5.png"}}]);
//# sourceMappingURL=component---src-pages-index-js-485e1c047fb0f405dde6.js.map